# Autoregressive Path Search - å®Œæ•´ä½¿ç”¨æŒ‡å—

## ğŸ“‹ å·²å®ç°çš„ç»„ä»¶

### âœ… æ ¸å¿ƒç»„ä»¶

1. **`src/samplers_autoregressive.py`** - BFSè·¯å¾„ç”Ÿæˆsampler
   - ä½¿ç”¨BFSæ‰¾åˆ°æ‰€æœ‰valid pathsï¼ˆconnectedæƒ…å†µï¼‰
   - é‡‡æ ·exploration pathsï¼ˆnot connectedæƒ…å†µï¼‰
   - å›ºå®šembeddingsç¡®ä¿ä¸€è‡´æ€§

2. **`src/models_autoregressive.py`** - è‡ªå›å½’Transformer
   - å‰2å±‚ï¼šBlock diagonal attentionï¼ˆå¤„ç†schemaï¼‰
   - å‰©ä½™å±‚ï¼šCausal attentionï¼ˆè‡ªå›å½’ç”Ÿæˆï¼‰
   - æ··åˆpositional encoding

3. **`src/tasks_autoregressive.py`** - Next token prediction task
   - CrossEntropyLoss with padding ignore
   - Token-level accuracy metric

4. **`src/beam_search.py`** - Beam searchæ¨ç†
   - å¯é…ç½®beam widthå’Œlength penalty
   - æ”¯æŒbatch inference
   - è®¡ç®—label accuracyå’Œexact match

5. **`src/train_autoregressive.py`** - è®­ç»ƒè„šæœ¬
   - å®Œæ•´çš„è®­ç»ƒå¾ªç¯
   - Wandb logging
   - Checkpoint saving
   - Beam search evaluation

6. **`src/conf/table_connectivity_autoregressive.yaml`** - é…ç½®æ–‡ä»¶

7. **`test_autoregressive.py`** - æµ‹è¯•è„šæœ¬ï¼ˆå·²éªŒè¯é€šè¿‡âœ“ï¼‰

### âœ… Schemaæ›´æ–°

- æ”¯æŒ `autoregressive_gpt2` model family
- æ”¯æŒ `table_connectivity_autoregressive` taskå’Œdata
- æ·»åŠ  `vocab_size` å’Œ `schema_len` å‚æ•°

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æµ‹è¯•æ‰€æœ‰ç»„ä»¶
```bash
cd /Users/yuexing/Dropbox/in-context-learning
python test_autoregressive.py
```

**é¢„æœŸè¾“å‡º**: æ‰€æœ‰æµ‹è¯•é€šè¿‡ âœ“

### 2. è®­ç»ƒæ¨¡å‹
```bash
cd /Users/yuexing/Dropbox/in-context-learning/src
python train_autoregressive.py --config conf/table_connectivity_autoregressive.yaml
```

### 3. ä¿®æ”¹é…ç½®

ç¼–è¾‘ `src/conf/table_connectivity_autoregressive.yaml`:

```yaml
model:
    V: 5              # è¡¨çš„æ•°é‡
    C: 3              # æ¯ä¸ªè¡¨çš„åˆ—æ•°
    n_embd: 256       # Embeddingç»´åº¦
    n_layer: 12       # Transformerå±‚æ•°
    n_head: 8         # Attention headæ•°é‡

training:
    batch_size: 64
    learning_rate: 0.0001
    train_steps: 2001
    num_training_examples: 100000
```

## ğŸ“Š æ•°æ®æ ¼å¼

### è¾“å…¥ (x)
```
[table1] [col1] [col2] [col3] [table2] ... [SEP] [query_col1] [query_col2] ...
```

### è¾“å‡º (y)
```
Connected case (label=1):
  [col1] [col3] [col5] [col7] [END]  # Complete path

Not connected case (label=-1):
  [col1] [col3] [col4] [END]  # Partial exploration path
```

### ç‰¹æ®ŠTokens
- `0`: PAD - å¡«å……token
- `1`: START - å¼€å§‹token
- `2`: SEP - åˆ†éš”ç¬¦
- `3`: END - ç»“æŸtoken
- `4+`: Column IDs

## ğŸ¯ æ¨¡å‹æ¶æ„è¯¦è§£

### Attention Pattern

#### First 2 Layers
```
Schema part:      [Block Diagonal]
Query part:       [Causal]
```

æ¯ä¸ªtableçš„C+1ä¸ªtokenså½¢æˆä¸€ä¸ªblockï¼Œåªèƒ½äº’ç›¸attendã€‚

#### Remaining Layers
```
All positions:    [Causal]
```

çº¯causal maskï¼Œæ¯ä¸ªä½ç½®åªèƒ½çœ‹åˆ°ä¹‹å‰çš„tokensã€‚

### Positional Encoding

- **Schema part (0-20)**: ä½ç§©positional embeddings
- **Path part (21+)**: æ ‡å‡†positional embeddings

## ğŸ”¬ Beam Searchæ¨ç†

### åŸºæœ¬ç”¨æ³•

```python
from beam_search import beam_search_inference

predictions = beam_search_inference(
    model=model,
    xs_batch=test_xs,
    column_embeddings=sampler.column_embeddings,
    beam_width=5,
    max_length=15,
    device='cuda'
)

# ç»“æœç»“æ„
for pred in predictions:
    tokens = pred['tokens']      # é¢„æµ‹çš„tokenåºåˆ—
    score = pred['score']        # Log probability score
    all_beams = pred['all_beams']  # æ‰€æœ‰beam candidates
```

### è¯„ä¼°

```python
from beam_search import evaluate_with_beam_search

accuracy, exact_match = evaluate_with_beam_search(
    model=model,
    xs_batch=xs,
    ys_batch=ys,
    labels_batch=labels,
    column_embeddings=column_embeddings,
    beam_width=5
)

print(f"Label Accuracy: {accuracy:.4f}")
print(f"Exact Match: {exact_match:.4f}")
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

### Wandb Metrics

è®­ç»ƒè¿‡ç¨‹ä¸­è®°å½•ï¼š
- `train/loss` - Next token prediction loss
- `train/accuracy` - Token-level accuracy
- `test/label_accuracy` - Final labelæ­£ç¡®ç‡
- `test/exact_match` - å®Œæ•´è·¯å¾„åŒ¹é…ç‡

### æŸ¥çœ‹è®­ç»ƒè¿›åº¦
```bash
# åœ¨wandb dashboardæŸ¥çœ‹
# æˆ–æŸ¥çœ‹ä¿å­˜çš„checkpoints
ls ../models/table_connectivity_autoregressive/
```

## ğŸ”§ é«˜çº§å®šåˆ¶

### ä¿®æ”¹BFSç­–ç•¥

ç¼–è¾‘ `src/samplers_autoregressive.py` ä¸­çš„ `_bfs_find_all_paths`:

```python
def _bfs_find_all_paths(self, G, table_cols, start_col, end_col, max_length=10):
    # ä¿®æ”¹max_lengthæ§åˆ¶è·¯å¾„é•¿åº¦
    # ä¿®æ”¹æ¢ç´¢ç­–ç•¥
    ...
```

### ä¿®æ”¹Beam Searchå‚æ•°

```python
searcher = BeamSearcher(
    model=model,
    beam_width=10,        # å¢åŠ beam width
    max_length=20,        # æ›´é•¿çš„ç”Ÿæˆ
    length_penalty=0.6    # è°ƒæ•´length penalty
)
```

### æ·»åŠ æ–°çš„Attention Pattern

ç¼–è¾‘ `src/models_autoregressive.py` ä¸­çš„ `_register_attention_masks`:

```python
def _register_attention_masks(self):
    # å®šåˆ¶ä½ è‡ªå·±çš„attention mask
    ...
```

## ğŸ“Š å®éªŒé…ç½®ç¤ºä¾‹

### å°è§„æ¨¡å®éªŒ (å¿«é€ŸéªŒè¯)
```yaml
model:
    V: 3
    C: 2
    n_embd: 128
    n_layer: 4
    n_head: 4

training:
    batch_size: 32
    train_steps: 500
```

### ä¸­ç­‰è§„æ¨¡å®éªŒ
```yaml
model:
    V: 5
    C: 3
    n_embd: 256
    n_layer: 8
    n_head: 8

training:
    batch_size: 64
    train_steps: 2000
```

### å¤§è§„æ¨¡å®éªŒ
```yaml
model:
    V: 10
    C: 5
    n_embd: 512
    n_layer: 12
    n_head: 16

training:
    batch_size: 128
    train_steps: 5000
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: Out of Memory
**è§£å†³**: å‡å° `batch_size` æˆ– `n_embd`

### Q2: è®­ç»ƒä¸æ”¶æ•›
**è§£å†³**: 
- é™ä½learning rate
- å¢åŠ train_steps
- æ£€æŸ¥æ•°æ®åˆ†å¸ƒ

### Q3: Beam searchå¤ªæ…¢
**è§£å†³**:
- å‡å°beam_width
- å‡å°max_length
- ä½¿ç”¨greedy decoding (beam_width=1)

## ğŸ“ å¯¹æ¯”ï¼šåŸå§‹ vs è‡ªå›å½’

| ç‰¹æ€§ | åŸå§‹Table Connectivity | è‡ªå›å½’Path Search |
|------|----------------------|-------------------|
| è¾“å‡º | Binary label (0/1) | Complete path |
| æ¨¡å‹ | Encoder-only | Autoregressive |
| Loss | Binary cross-entropy | Next token prediction |
| æ¨ç† | Forward pass | Beam search |
| å¯è§£é‡Šæ€§ | ä½ | é«˜ï¼ˆçœ‹åˆ°æœç´¢è·¯å¾„ï¼‰ |
| è®­ç»ƒæ ·æœ¬ | 1 per query | Multiple per query |
| è®¡ç®—å¤æ‚åº¦ | O(N) | O(N Ã— B Ã— L) |

## ğŸ“ ç†è®ºèƒŒæ™¯

### BFSè®­ç»ƒæ•°æ®ç”Ÿæˆ

1. **Connected cases**: 
   - ä½¿ç”¨BFSæ‰¾åˆ°æ‰€æœ‰ä»col1åˆ°col2çš„è·¯å¾„
   - æ¯æ¡è·¯å¾„ä½œä¸ºä¸€ä¸ªè®­ç»ƒæ ·æœ¬
   - Label = 1

2. **Not connected cases**:
   - BFSæ¢ç´¢è¿‡ç¨‹ä¸­çš„partial paths
   - éšæœºé‡‡æ ·ä¸€éƒ¨åˆ†ä½œä¸ºè´Ÿæ ·æœ¬
   - Label = -1

### Length Normalization

ä½¿ç”¨Google NMTè®ºæ–‡ä¸­çš„å…¬å¼ï¼š
```
score = log_prob / ((5 + length) / 6) ^ alpha
```

é¿å…beam searchåå‘çŸ­åºåˆ—ã€‚

## ğŸš€ ä¸‹ä¸€æ­¥

1. **å®éªŒä¸åŒçš„Vå’ŒCå€¼**
2. **å°è¯•ä¸åŒçš„attention patterns**
3. **å¯¹æ¯”ä¸åŒçš„beam searchç­–ç•¥**
4. **å¯è§†åŒ–ç”Ÿæˆçš„è·¯å¾„**
5. **åˆ†ææ¨¡å‹å­¦åˆ°çš„graph structure**

## ğŸ“š ç›¸å…³æ–‡ä»¶

- ä¸»è¦ä»£ç : `src/samplers_autoregressive.py`, `src/models_autoregressive.py`, `src/beam_search.py`
- è®­ç»ƒè„šæœ¬: `src/train_autoregressive.py`
- é…ç½®: `src/conf/table_connectivity_autoregressive.yaml`
- æµ‹è¯•: `test_autoregressive.py`
- æ–‡æ¡£: `AUTOREGRESSIVE_PATH_SEARCH_README.md`, `AUTOREGRESSIVE_USAGE_GUIDE.md`

---

## âœ… éªŒè¯æ¸…å•

- [x] Samplerå®ç°å¹¶æµ‹è¯•
- [x] Modelå®ç°å¹¶æµ‹è¯•
- [x] Taskå®ç°å¹¶æµ‹è¯•
- [x] Beam searchå®ç°å¹¶æµ‹è¯•
- [x] Training scriptå®ç°
- [x] Configurationæ–‡ä»¶åˆ›å»º
- [x] Schemaæ›´æ–°
- [x] é›†æˆæµ‹è¯•é€šè¿‡
- [x] æ–‡æ¡£å®Œæ•´

**çŠ¶æ€**: æ‰€æœ‰ç»„ä»¶å·²å®ç°å¹¶æµ‹è¯•é€šè¿‡ âœ“

å¼€å§‹è®­ç»ƒå§ï¼ğŸš€

