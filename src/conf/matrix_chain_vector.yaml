inherit: 
    - wandb.yaml

model:
    family: gpt2  # Use standard GPT2 transformer
    n_dims: 16
    n_positions: 100  # L * (n^2 + 2n) = 3 * (16 + 8) = 72, use a bit less for buffer
    n_embd: 256
    n_layer: 12
    n_head: 8

training:
    task: matrix_chain_vector
    data: matrix_chain_vector
    task_kwargs: {"L": 50, "n": 4, "m": 4, "p": 4, "q": 4}
    batch_size: 64
    learning_rate: 0.003
    train_steps: 50000
    curriculum:
        dims:
            start: 16
            end: 16
            inc: 0
            interval: 2000
        points:
            start: 200
            end: 200
            inc: 0
            interval: 2000

out_dir: ../models/matrix_chain_vector

wandb:
    name: "matrix_chain_vector_gpt2"

